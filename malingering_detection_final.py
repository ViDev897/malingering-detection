# -*- coding: utf-8 -*-
"""Malingering Detection Final

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1S-0dMmAdsrcDfuGT8z6yqaqA2Usj2BUy
"""

# TOMM-like AI Malingering Detection Model
# (Full rewritten version based on your PHQ/GAD script)

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import joblib
import os
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.impute import SimpleImputer
from sklearn.pipeline import Pipeline
from sklearn.metrics import (
    roc_auc_score, roc_curve, confusion_matrix, classification_report
)
from datetime import datetime
import re

# Import XGBoost
import xgboost as xgb

# Install fpdf if not already installed
try:
    from fpdf import FPDF
except ImportError:
    print("fpdf not found, installing...")
    !pip install fpdf > /dev/null # Suppress output
    from fpdf import FPDF

# =============================
# PATHS
# =============================
DATA_PATH = "/content/tomm_lie_detection_template.csv"  # User will upload this dataset
MODEL_PATH = "tomm_lie_detector_model.joblib"
PLOTS_DIR = "tomm_lie_plots"
os.makedirs(PLOTS_DIR, exist_ok=True)

# =============================
# STEP 1: LOAD & CLEAN DATA
# =============================
print("\nüîπ Loading dataset...")
df = pd.read_csv(DATA_PATH)

# Ensure numeric encoding for answers (A=0, B=1)
# TOMM-like question bank
questions = {
    1: "Which one is a fruit? (A. Apple / B. Stone)",
    2: "Which one is an animal? (A. Dog / B. Table)",
    3: "Which object do people wear? (A. Shoes / B. Grass)",
    4: "Which one is used for writing? (A. Pen / B. Spoon)",
    5: "Which one can fly? (A. Bird / B. Chair)",
    6: "Which one is a vehicle? (A. Car / B. Banana)",
    7: "Which is a common drink? (A. Water / B. Sand)",
    8: "Which one is bigger? (A. Elephant / B. Ant)",
    9: "Which one is a color? (A. Blue / B. Fork)",
    10: "Which one is eaten as food? (A. Rice / B. Pillow)",
    11: "Which is a common pet? (A. Cat / B. Rock)",
    12: "Which item can you read? (A. Book / B. Cup)",
    13: "Which one is used to cut? (A. Scissors / B. Blanket)",
    14: "Which is a mode of transport? (A. Bus / B. Leaf)",
    15: "Which is used to make calls? (A. Phone / B. Shoe)",
    16: "Which is found in the sky? (A. Sun / B. Bottle)",
    17: "Which is used to cook? (A. Stove / B. Shoes)",
    18: "Which is a metal? (A. Iron / B. Bread)",
    19: "Which one grows on trees? (A. Mango / B. Wallet)",
    20: "Which one is cold? (A. Ice / B. Fire)",
    21: "Which one is a large feline? (A. Lion / B. Duck)", # Modified
    22: "Which shape did you see? (A. Triangle / B. Pentagon)",
    23: "Object used for timekeeping: (A. Clock / B. Hammer)",
    24: "Which fruit appeared? (A. Orange / B. Coconut)",
    25: "Which one hops? (A. Rabbit / B. Snake)", # Modified
    26: "Which one protects from rain? (A. Umbrella / B. Screwdriver)", # Modified
    27: "Which one is a celestial body? (A. Star / B. Arrow)", # Modified
    28: "Which household item was shown? (A. Cup / B. Brush)",
    29: "Which one has two wheels? (A. Bicycle / B. Train)", # Modified
    30: "Which food item appeared? (A. Bread / B. Onion)",
    31: "Which one is typically red and a symbol of love? (A. Circle / B. Heart)", # Modified
    32: "Which living thing appeared? (A. Tree / B. Robot)",
    33: "Which device appeared? (A. Laptop / B. Iron)",
    34: "Which animal was seen? (A. Fish / B. Tiger)",
    35: "Which tool was shown? (A. Wrench / B. Mirror)",
    36: "Which object for sitting appeared? (A. Chair / B. Bucket)",
    37: "Which pattern goes back and forth in sharp turns? (A. Zigzag / B. Spiral)", # Modified
    38: "Which sports item was shown? (A. Ball / B. Bat)",
    39: "Which water-related object appeared? (A. Boat / B. Bottle)",
    40: "Which sky-related picture was displayed? (A. Cloud / B. River)",
    41: "Is water wet? (A. Yes / B. No)",
    42: "Which is heavier? (A. Rock / B. Paper)",
    43: "Which is used for sleeping? (A. Bed / B. Plate)",
    44: "Which day comes after Monday? (A. Tuesday / B. Saturday)",
    45: "Which animal barks? (A. Dog / B. Cow)",
    46: "What color is the sky normally? (A. Blue / B. Pink)",
    47: "Which is used for eating? (A. Spoon / B. Brick)",
    48: "Which number is bigger? (A. 10 / B. 2)",
    49: "What do humans breathe? (A. Air / B. Water)",
    50: "Is fire hot? (A. Yes / B. No)"
}

# Add section headers during questioning
for i in range(1, 51):
    # Section headers
    if i == 1:
        print("\n===== SECTION A ‚Äî Recognition Memory (Very Easy) =====")
    elif i == 21:
        print("\n===== SECTION B ‚Äî Visual Memory (Moderate Difficulty) =====")
    elif i == 41:
        print("\n===== SECTION C ‚Äî Consistency & Attention Checks =====")
    col = f"Q{i}"
    df[col] = df[col].map({"A": 0, "B": 1}).astype(float)

# Handle missing values
imputer = SimpleImputer(strategy="median")
question_cols = [f"Q{i}" for i in range(1, 51)]
df[question_cols] = imputer.fit_transform(df[question_cols])

# =============================
# STEP 2: SECTION SCORING RULES
# =============================
print("Scoring questionnaire sections...")
df['section_a'] = df[[f"Q{i}" for i in range(1, 21)]].sum(axis=1)
df['section_b'] = df[[f"Q{i}" for i in range(21, 41)]].sum(axis=1)
df['section_c'] = df[[f"Q{i}" for i in range(41, 51)]].sum(axis=1)

# If no provided labels, auto-generate
if 'malingering_label' not in df.columns:
    print("‚ö†Ô∏è No labels found ‚Äî generating automatic labels based on scoring criteria.")
    df['malingering_label'] = np.where(
        (df['section_a'] <= 14) |
        (df['section_b'] <= 12) |
        (df['section_c'] <= 7),
        1, 0
    )

print("Dataset size:", df.shape)

# =============================
# STEP 3: MODEL TRAINING
# =============================
print("Training XGBoost model...")

X = df[question_cols]
y = df['malingering_label']

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, stratify=y, random_state=42
)

# Calculate scale_pos_weight for XGBoost to handle class imbalance
neg_count = y_train.value_counts()[0]
pos_count = y_train.value_counts()[1]
scale_pos_weight_value = neg_count / pos_count

model = Pipeline([
    ("imputer", SimpleImputer(strategy="median")),
    ("scaler", StandardScaler()),
    ("clf", xgb.XGBClassifier(objective='binary:logistic', eval_metric='logloss', use_label_encoder=False,
                              n_estimators=300, random_state=42, scale_pos_weight=scale_pos_weight_value))
])

model.fit(X_train, y_train)
y_pred = model.predict(X_test)
y_proba = model.predict_proba(X_test)[:, 1]
auc = roc_auc_score(y_test, y_proba)

print(f"\n‚úÖ Model trained successfully. ROC-AUC: {auc:.3f}")
print(classification_report(y_test, y_pred))

joblib.dump({"model": model, "features": question_cols}, MODEL_PATH)
print(f"üíæ Model saved as {MODEL_PATH}\n")

# =============================
# STEP 4: VISUALIZATIONS
# =============================
print("Saving plots...")

# ROC Curve
fpr, tpr, _ = roc_curve(y_test, y_proba)
plt.figure(figsize=(6, 5))
plt.plot(fpr, tpr, label=f"AUC={auc:.2f}")
plt.plot([0, 1], [0, 1], '--', color='gray')
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.title("ROC Curve ‚Äî Malingering Detection")
plt.legend()
plt.tight_layout()
plt.savefig(f"{PLOTS_DIR}/roc_curve.png")
plt.close()

# Confusion Matrix
cm = confusion_matrix(y_test, y_pred)
plt.figure(figsize=(4, 3))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
plt.title("Confusion Matrix")
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.tight_layout()
plt.savefig(f"{PLOTS_DIR}/confusion_matrix.png")
plt.close()

print("üìä Plots saved!")

# =============================
# STEP 5: VISUALIZATION BASED ON USER RESPONSES
# =============================

def generate_user_plots(answers, prob, pred):
    import matplotlib.pyplot as plt
    import seaborn as sns
    import numpy as np
    import os

    # Create output directory
    USER_PLOT_DIR = "user_response_plots"
    os.makedirs(USER_PLOT_DIR, exist_ok=True)

    # --- Plot 1: Bar chart of all 50 answers ---
    plt.figure(figsize=(14,5))
    sns.barplot(x=list(range(1,51)), y=answers, palette="viridis")
    plt.title("User Responses (A=0, B=1)")
    plt.xlabel("Question Number")
    plt.ylabel("Response Value")
    plt.tight_layout()
    plt.savefig(f"{USER_PLOT_DIR}/responses_barplot.png")
    plt.close()

    # --- Plot 2: Section Scores ---
    section_a = sum(answers[:20])
    section_b = sum(answers[20:40])
    section_c = sum(answers[40:50])

    plt.figure(figsize=(6,5))
    sns.barplot(x=["Section A","Section B","Section C"], y=[section_a, section_b, section_c], palette="coolwarm")
    plt.title("Section Scores")
    plt.ylabel("Score")
    plt.tight_layout()
    plt.savefig(f"{USER_PLOT_DIR}/section_scores.png")
    plt.close()

    # --- Plot 3: Probability Gauge ---
    plt.figure(figsize=(6,1.5))
    plt.barh(["Malingering Probability"],[prob*100], color="red" if pred==1 else "green")
    plt.xlim(0,100)
    plt.tight_layout()
    plt.savefig(f"{USER_PLOT_DIR}/probability_gauge.png")
    plt.close()

    print(f"üìä User plots saved in: {USER_PLOT_DIR}/")

# =============================
# STEP 6: PDF REPORT GENERATION
# =============================
def generate_pdf_report(answers, prob, pred):
    section_a = sum(answers[:20])
    section_b = sum(answers[20:40])
    section_c = sum(answers[40:50])

    pdf = FPDF()
    pdf.add_page()
    pdf.set_font("Arial", size=12)

    pdf.cell(200, 10, txt="TOMM-Like Malingering Detection Report", ln=1, align='C')
    pdf.ln(5)

    pdf.cell(200, 10, txt=f"Malingering Probability: {prob*100:.2f}%", ln=1)
    pdf.cell(200, 10, txt=f"Prediction: {'MALINGERING' if pred==1 else 'VALID EFFORT'}", ln=1)
    pdf.ln(5)

    pdf.cell(200, 10, txt="Section Scores:", ln=1)
    pdf.cell(200, 8, txt=f"Section A: {section_a}/20", ln=1)
    pdf.cell(200, 8, txt=f"Section B: {section_b}/20", ln=1)
    pdf.cell(200, 8, txt=f"Section C: {section_c}/10", ln=1)
    pdf.ln(5)

    pdf.cell(200, 10, txt="Plots Attached Below", ln=1)

    # Add plots
    pdf.image("user_response_plots/responses_barplot.png", w=180)
    pdf.ln(5)
    pdf.image("user_response_plots/section_scores.png", w=180)
    pdf.ln(5)
    pdf.image("user_response_plots/probability_gauge.png", w=180)

    OUTPUT = "tomm_report.pdf"
    pdf.output(OUTPUT)
    print(f"üìÑ PDF report generated: {OUTPUT}")

# =============================
# STEP 7: HEATMAP COMPARISON WITH NORMATIVE PATTERNS
# =============================

def generate_normative_heatmap(answers):
    import numpy as np
    import matplotlib.pyplot as plt
    import seaborn as sns
    import os

    # Example normative correctness rates
    normative = np.concatenate([
        0.99 * np.ones(20),
        0.85 * np.ones(20),
        0.98 * np.ones(10)
    ])

    user = np.array(answers)

    diff = normative - user

    plt.figure(figsize=(12,2))
    sns.heatmap([diff], cmap="coolwarm", cbar=True, xticklabels=list(range(1,51)))
    plt.title("Normative vs User Response Deviation Heatmap")
    plt.tight_layout()
    path = "user_response_plots/normative_heatmap.png"
    plt.savefig(path)
    plt.close()

    print(f"üî• Normative comparison heatmap saved: {path}")

# =============================
# STEP 8: CHATBOT FINAL INTEGRATION
# =============================

def ask_question(qtext):
    while True:
        ans = input(qtext + " (A/B): ").strip().upper()
        if ans in ["A", "B"]:
            return 0 if ans == "A" else 1
        print("Invalid input. Enter A or B.")


def run_chatbot():
    print("\nü§ñ TOMM-Like Malingering Chatbot Initialized!")
    print("Answer the following 50 forced-choice questions. Type A or B.\n")

    answers = []
    for i in range(1, 51):
        # Get the full question text from the global 'questions' dictionary
        full_q_text = questions.get(i, f"Question {i} (Text not found)")
        ans = ask_question(full_q_text)
        answers.append(ans)

    model_data = joblib.load(MODEL_PATH)
    model = model_data["model"]

    X_pred = np.array([answers])
    prob = model.predict_proba(X_pred)[0][1]
    pred = model.predict(X_pred)[0]

    print("\n======== RESULT =======-")

    # Section-wise scoring
    section_a = sum(answers[:20])
    section_b = sum(answers[20:40])
    section_c = sum(answers[40:50])

    print(f"Section A Score (Q1‚Äì20): {section_a}/20 ‚Üí {'PASS' if section_a>14 else 'FAIL'}")
    print(f"Section B Score (Q21‚Äì40): {section_b}/20 ‚Üí {'PASS' if section_b>12 else 'FAIL'}")
    print(f"Section C Score (Q41‚Äì50): {section_c}/10 ‚Üí {'PASS' if section_c>7 else 'FAIL'}")
    print("--------------------------------------")

    # Interpretation messages
    if section_a <= 14:
        print("‚ö†Ô∏è Section A: Very low accuracy on easy items ‚Äî possible malingering.")
    if section_b <= 12:
        print("‚ö†Ô∏è Section B: Below expected memory accuracy ‚Äî reduced effort suspected.")
    if section_c <= 7:
        print("‚ö†Ô∏è Section C: High inconsistency ‚Äî strong malingering indicator.")
    if section_a>14 and section_b>12 and section_c>7:
        print("‚úÖ All sections passed ‚Äî performance consistent with genuine effort.")

    # ASCII Bar Graph
    print("\nSECTION SCORE VISUALIZATION:")
    def bar(n, maxn): return "‚ñà" * int((n/maxn)*20)
    print(f"A [ {bar(section_a,20)} ] {section_a}/20")
    print(f"B [ {bar(section_b,20)} ] {section_b}/20")
    print(f"C [ {bar(section_c,10)} ] {section_c}/10")
    print("--------------------------------------")

    # Adaptive suggestions
    if section_a<=14 and section_b<=12:
        print("Adaptive Note: Recommend retesting with validated effort measures.")
    elif section_a<=14 and section_c<=7:
        print("Adaptive Note: Low easy scores + inconsistency suggest deliberate low effort.")
    elif section_b<=12:
        print("Adaptive Note: Additional visual memory tests advised.")

    print("========================\n")

    # Generate plots and PDF report
    generate_user_plots(answers, prob, pred)
    generate_normative_heatmap(answers)
    generate_pdf_report(answers, prob, pred)


# =============================
# STEP 9: DEMO MODE ‚Äî PREDEFINED SAMPLE CASES
# =============================

def demo_cases():
    print("\n================ DEMO CASES ================")

    sample_cases = {
        "Case 1 ‚Äî High Malingering": {
            "answers": [0]*5 + [1]*3 + [0]*12 +  # low Section A
                       [0,1,0,1]*5 +              # weak Section B
                       [1,1,0,1,0,1,0,1,0,1],     # inconsistent Section C
        },
        "Case 2 ‚Äî Moderate Malingering": {
            "answers": [1]*14 + [0]*6 +          # borderline A
                       [0]*11 + [1]*9 +          # low B
                       [1,0,1,0,1,0,1,0,1,0],     # inconsistent C
        },
        "Case 3 ‚Äî Valid Effort": {
            "answers": [1]*20 +                  # perfect A
                       [1]*17 + [0]*3 +           # strong B
                       [1]*10                     # perfect C
        },
        "Case 4 ‚Äî Low Malingering Probability": {
            "answers": [1]*18 + [0]*2 +          # normal A
                       [1]*14 + [0]*6 +           # normal B
                       [1]*9 + [0]                # near perfect C
        }
    }

    model_data = joblib.load(MODEL_PATH)
    model = model_data["model"]

    for case_name, data in sample_cases.items():
        ans = data["answers"]
        X_pred = np.array([ans])
        prob = model.predict_proba(X_pred)[0][1]
        pred = model.predict(X_pred)[0]

        print(f"\n--- {case_name} ---")
        print(f"Probability of Malingering: {prob*100:.2f}%")
        print(f"Prediction: {'MALINGERING' if pred == 1 else 'VALID EFFORT'}")


if __name__ == "__main__":
    print("Choose Mode:\n1. Chatbot Mode\n2. Demo Mode (4 predefined cases)")
    mode = "1" # Changed to directly select Chatbot Mode
    if mode == "2":
        demo_cases()
    else:
        run_chatbot()